# rag_answer.py  — chatty + hybrid fallback for blocks/contacts

import os, sys, re, argparse
from pathlib import Path
from typing import List, Dict, Any, Tuple
import sql_router as SR

from langchain_community.vectorstores import FAISS
from langchain_core.embeddings import Embeddings as LCEmbeddings

# ---------------- Embeddings ----------------
class GeminiLCEmbeddings(LCEmbeddings):
    def __init__(self, model: str = "models/text-embedding-004", api_key_env: str = "GEMINI_API_KEY"):
        import google.generativeai as genai
        api_key = os.getenv(api_key_env)
        if not api_key:
            print("[ERROR] GEMINI_API_KEY not set.")
            sys.exit(1)
        genai.configure(api_key=api_key)
        self.genai = genai
        self.model = model
    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        return [self.genai.embed_content(model=self.model, content=t)["embedding"] for t in texts]
    def embed_query(self, text: str) -> List[float]:
        return self.genai.embed_content(model=self.model, content=text)["embedding"]

# ---------------- Vector load/search ----------------
def load_store(index_dir: Path, collection: str, emb: LCEmbeddings) -> FAISS:
    return FAISS.load_local(
        str(index_dir),
        embeddings=emb,
        index_name=collection,
        allow_dangerous_deserialization=True
    )

def retrieve(store: FAISS, query: str, k: int = 40):
    return store.similarity_search(query, k=k)

def _keyword_score(text: str, q: str) -> int:
    qwords = [w for w in re.findall(r"[a-z0-9]+", q.lower()) if len(w) > 2]
    t = text.lower()
    return sum(t.count(w) for w in qwords)

def _postfilter_and_rerank(docs, query: str, want_hostel: bool = False, topn: int = 12):
    def tok(md):
        name = (md.get("source_file") or "").lower()
        return {
            "lh": "lh" in name or "ladies" in name or "girls" in name or "women" in name,
            "mh": "mh" in name or "mens" in name or "boys" in name,
            "hostel": "hostel" in name,
        }
    scored = []
    for d in docs:
        md = d.metadata or {}
        t = tok(md)
        s = 0
        if want_hostel and t["hostel"]: s += 2
        s += _keyword_score(d.page_content or "", query)
        scored.append((s, d))
    scored.sort(key=lambda x: x[0], reverse=True)
    return [d for s, d in scored][:topn]

def _faiss_context(index_dir: Path, collection: str, query: str, k: int = 20) -> Tuple[str, List[str]]:
    emb = GeminiLCEmbeddings()
    store = load_store(index_dir, collection, emb)
    docs = retrieve(store, query, k=k)
    docs = _postfilter_and_rerank(docs, query, want_hostel=True, topn=min(k, 15))
    ctx_lines, sources = [], []
    for d in docs:
        md = d.metadata or {}
        src = md.get("source_file") or md.get("source_title") or "unknown"
        sources.append(src)
        ctx_lines += [d.page_content[:1200] if d.page_content else ""]
    return "\n\n".join(ctx_lines), list(dict.fromkeys(sources))

# ---------------- Extraction helpers ----------------
def _money_to_float(s: str) -> float:
    if not s: return float("nan")
    t = re.sub(r"[^\d.]", "", s.replace(",", ""))
    return float(t) if t else float("nan")

def _summarize_rows(cols: List[str], rows: List[List[str]], filters: Dict[str, Any]) -> List[str]:
    if not rows: return []
    # locate columns
    def idx(name): return cols.index(name) if name in cols else -1
    i_total = idx("Total")
    i_rm    = idx("Room+Mess")
    i_curr  = idx("Curr")
    i_gen   = idx("Gender")
    i_lvl   = idx("Level")
    i_cat   = idx("Category")
    # choose amount prefer total>room+mess
    amounts: Dict[str, List[float]] = {}
    for r in rows:
        curr = (r[i_curr] if i_curr >= 0 else "").strip() or "INR"
        amount_cell = r[i_total] if (i_total >= 0 and r[i_total]) else (r[i_rm] if i_rm >= 0 else "")
        val = _money_to_float(amount_cell)
        if not (val != val):  # not NaN
            amounts.setdefault(curr, []).append(val)

    bullets = []
    who = []
    if filters.get("gender"):  who.append(filters["gender"])
    if filters.get("level"):   who.append(filters["level"])
    if filters.get("category"):who.append(filters["category"])
    if filters.get("ay"):      who.append(filters["ay"])
    who_txt = " ".join(w for w in who if w)

    for curr, arr in amounts.items():
        if not arr: continue
        low, high = min(arr), max(arr)
        if curr.upper()=="INR":
            bullets.append(f"{who_txt or 'Overall'}: ₹{int(low):,} – ₹{int(high):,} (Total).")
        else:
            bullets.append(f"{who_txt or 'Overall'}: {curr} {low:,.0f} – {high:,.0f} (Total).")
    if not bullets and len(rows)>0:
        bullets.append(f"{len(rows)} matching fee rows.")
    return bullets[:4]

def _extract_blocks(text: str) -> List[str]:
    if not text: return []
    codes = re.findall(r"\b(?:MH|LH)[A-Z0-9\-]{1,3}\b", text)  # e.g., MH-A, MHA, LH1
    named = re.findall(r"(?i)\b(?:Men|Ladies)\s+Hostel\s*(?:[A-Za-z0-9\-]+)?", text)
    out = sorted(set(codes + named))
    return out[:40]

def _extract_contacts(text: str) -> List[Tuple[str, str, str]]:
    if not text: return []
    phones = re.findall(r"(?:(?:\+?\d{1,3}[-\s]?)?\d{10,})", text)
    emails = re.findall(r"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}", text)
    # Try to pick role hints around the numbers
    triples = []
    for ph in phones[:20]:
        # look for a nearby role keyword within 40 chars
        m = re.search(r"(?i)(warden|supervisor|superintendent|hostel office|admin|care taker).{0,40}?" + re.escape(ph), text)
        role = (m.group(1).title() if m else "Contact")
        triples.append(("", role, ph))
    for em in emails[:20]:
        m = re.search(r"(?i)(warden|supervisor|superintendent|hostel office|admin|care taker).{0,40}?" + re.escape(em), text)
        role = (m.group(1).title() if m else "Email")
        triples.append(("", role, em))
    # de-dup by value
    seen, out = set(), []
    for name, role, val in triples:
        if val in seen: continue
        seen.add(val)
        out.append((name, role, val))
    return out[:40]

def _render_table_md(title: str, cols: List[str], rows: List[List[str]]) -> str:
    out = []
    if title: out.append(f"**{title}**")
    out.append("| " + " | ".join(cols) + " |")
    out.append("|" + "|".join(["---"]*len(cols)) + "|")
    for r in rows:
        out.append("| " + " | ".join("" if c is None else str(c) for c in r) + " |")
    out.append("")
    return "\n".join(out)

# ---------------- Main answer logic ----------------
def answer_query(index_dir: Path, collection: str, query: str) -> str:
    sr_intent = SR.detect_structured_intent(query)
    f = SR.parse_filters(query)

    # ---------- Structured SQL routes ----------
    if sr_intent in ("tabular", "contacts", "blocks"):
        if sr_intent == "contacts":
            data = SR.sql_block_contacts(f)
            rows = data["table"]["rows"]
            if not rows:
                # Hybrid fallback: scrape FAISS for contacts
                ctx, sources = _faiss_context(index_dir, collection, query, k=12)
                contacts = _extract_contacts(ctx)
                if contacts:
                    cols = ["Name/Block", "Role", "Phone/Email"]
                    rows = [[n or "", r, v] for (n, r, v) in contacts]
                    md = _render_table_md("Hostel Contacts (from PDFs)", cols, rows)
                    if sources:
                        md += "\n*Sources:* " + ", ".join(sources[:5])
                    return md + "\n\n*Note: Mixed from SQLite and retrieved PDFs.*"
                # nothing found
                return "**Hostel Contacts**\n\n_No contact details found in SQLite or PDFs._"

        elif sr_intent == "blocks":
            data = SR.sql_list_blocks(f)
            rows = data["table"]["rows"]
            if not rows:
                # Hybrid fallback: look for block codes/names in PDFs
                ctx, sources = _faiss_context(index_dir, collection, "hostel block names MH LH blocks", k=15)
                blocks = _extract_blocks(ctx)
                if blocks:
                    md = "**Hostel Blocks (from PDFs)**\n" + "\n".join(f"- {b}" for b in blocks)
                    if sources:
                        md += "\n\n*Sources:* " + ", ".join(sources[:5])
                    return md + "\n\n*Note: Mixed from SQLite and retrieved PDFs.*"
                return "**Hostel Blocks**\n\n_No block names found in SQLite or PDFs._"

        else:
            data = SR.sql_hostel_overview(f)

        # Dedup + hide "Source"
        cols = data["table"]["columns"][:]
        rows = [r[:] for r in data["table"]["rows"]]
        if "Source" in cols:
            si = cols.index("Source")
            cols = cols[:si] + cols[si+1:]
            rows = [[c for j, c in enumerate(r) if j != si] for r in rows]

        # Deduplicate identical rows
        seen = set(); clean_rows = []
        for r in rows:
            key = tuple("" if c is None else str(c).strip() for c in r)
            if key in seen: continue
            seen.add(key)
            clean_rows.append(r)

        # Chatty summary (top)
        bullets = _summarize_rows(cols, clean_rows, f)
        intro = ""
        if bullets:
            intro = "**Answer (quick summary):**\n" + "\n".join(f"- {b}" for b in bullets) + "\n\n"

        md = _render_table_md(data["table"].get("title","Results"), cols, clean_rows[:60])
        quick = ""
        if data.get("bullets"):
            quick = "\n**Quick overview:**\n" + "\n".join(f"- {b}" for b in data["bullets"])
        return intro + md + quick + "\n\n*Note: Structured answers come from your SQLite DB built from official PDFs.*"

    # ---------- Non-structured: FAISS fallback ----------
    emb = GeminiLCEmbeddings()
    store = load_store(index_dir, collection, emb)
    docs = retrieve(store, query, k=40)
    docs = _postfilter_and_rerank(docs, query, want_hostel=True, topn=10)

    ctx_lines, sources = [], []
    for d in docs:
        md = d.metadata or {}
        src = md.get("source_file") or md.get("source_title") or "unknown"
        sources.append(src)
        ctx_lines += [d.page_content[:600] if d.page_content else ""]

    # Minimal “chatty” summary using the retrieved text only
    text = "\n\n".join(ctx_lines)
    snippet = (text[:600] + "…") if len(text) > 600 else text
    out = []
    out.append("**Answer (from PDFs):**")
    out.append(snippet if snippet else "_Couldn’t derive a concise summary from the retrieved context._")
    if sources:
        out.append("\n*Sources:* " + ", ".join(list(dict.fromkeys(sources))[:5]))
    out.append("\n*Note: Answers are generated only from your ingested official PDFs.*")
    return "\n".join(out)

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--index_dir", required=True)
    ap.add_argument("--collection", default="vit_faq_vellore")
    ap.add_argument("--emb", choices=["gemini"], default="gemini")
    ap.add_argument("--q", required=True)
    args = ap.parse_args()
    print("\n" + answer_query(Path(args.index_dir), args.collection, args.q) + "\n")

if __name__ == "__main__":
    main()
