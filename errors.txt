# app/utils/fallback_rag.py — FAISS retrieval + Gemini embeddings + simple summaries

import os, sys, re
from pathlib import Path
from typing import List, Tuple
from langchain_community.vectorstores import FAISS
from langchain_core.embeddings import Embeddings as LCEmbeddings

class GeminiLCEmbeddings(LCEmbeddings):
    def __init__(self, model: str = "models/text-embedding-004", api_key_env: str = "GEMINI_API_KEY"):
        import google.generativeai as genai
        api_key = os.getenv(api_key_env)
        if not api_key:
            print("[ERROR] GEMINI_API_KEY not set.")
            sys.exit(1)
        genai.configure(api_key=api_key)
        self.genai = genai
        self.model = model
    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        return [self.genai.embed_content(model=self.model, content=t)["embedding"] for t in texts]
    def embed_query(self, text: str) -> List[float]:
        return self.genai.embed_content(model=self.model, content=text)["embedding"]

def _keyword_score(text: str, q: str) -> int:
    qwords = [w for w in re.findall(r"[a-z0-9]+", q.lower()) if len(w) > 2]
    t = text.lower()
    return sum(t.count(w) for w in qwords)

def _postfilter_and_rerank(docs, query: str, topn: int = 12):
    scored = []
    for d in docs:
        s = _keyword_score(d.page_content or "", query)
        scored.append((s, d))
    scored.sort(key=lambda x: x[0], reverse=True)
    return [d for s, d in scored][:topn]

def _summarize(text: str) -> str:
    blob = re.sub(r"\s+", " ", text or "").strip()
    if not blob: return ""
    parts = re.split(r"(?<=[.!?])\s+", blob)
    return " ".join(parts[:8])

def faiss_answer_or_summary(index_dir: Path, collection: str, q: str) -> str:
    emb = GeminiLCEmbeddings()
    store = FAISS.load_local(str(index_dir), embeddings=emb, index_name=collection, allow_dangerous_deserialization=True)
    docs = store.similarity_search(q, k=40)
    docs = _postfilter_and_rerank(docs, q, topn=12)
    if not docs:
        return "_I couldn’t find enough context to answer that from your PDFs._"
    ctx, sources = [], []
    for d in docs:
        md = d.metadata or {}
        src = md.get("source_file") or md.get("source_title") or "unknown"
        sources.append(src); ctx.append(d.page_content or "")
    text = "\n\n".join(ctx)
    para = _summarize(text)
    srcs = []
    seen = set()
    for s in sources:
        if s and s not in seen:
            seen.add(s); srcs.append(s)
            if len(srcs) >= 5: break
    return f"**Answer (from your PDFs):** {para}\n\n*Sources:* {', '.join(srcs)}"
