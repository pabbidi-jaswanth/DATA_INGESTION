# rag_answer.py  (only change is: route "blocks" to SR.sql_list_blocks)

import os, sys, re, argparse
from pathlib import Path
from typing import List, Dict, Any
import sql_router as SR

from langchain_community.vectorstores import FAISS
from langchain_core.embeddings import Embeddings as LCEmbeddings

class GeminiLCEmbeddings(LCEmbeddings):
    def __init__(self, model: str = "models/text-embedding-004", api_key_env: str = "GEMINI_API_KEY"):
        import google.generativeai as genai
        api_key = os.getenv(api_key_env)
        if not api_key:
            print("[ERROR] GEMINI_API_KEY not set.")
            sys.exit(1)
        genai.configure(api_key=api_key)
        self.genai = genai
        self.model = model
    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        return [self.genai.embed_content(model=self.model, content=t)["embedding"] for t in texts]
    def embed_query(self, text: str) -> List[float]:
        return self.genai.embed_content(model=self.model, content=text)["embedding"]

def load_store(index_dir: Path, collection: str, emb: LCEmbeddings) -> FAISS:
    return FAISS.load_local(str(index_dir), embeddings=emb, index_name=collection, allow_dangerous_deserialization=True)

def retrieve(store: FAISS, query: str, k: int = 40):
    return store.similarity_search(query, k=k)

def keyword_score(text: str, q: str) -> int:
    qwords = [w for w in re.findall(r"[a-z0-9]+", q.lower()) if len(w) > 2]
    t = text.lower()
    return sum(t.count(w) for w in qwords)

def postfilter_and_rerank(docs, filt: Dict[str, Any], query: str, topn: int = 12):
    def ok(md):
        if "domain" in filt and md.get("domain") and md["domain"].lower()!=filt["domain"].lower():
            return False
        if "category" in filt and md.get("category") and md["category"].lower()!=filt["category"].lower():
            return False
        return True
    docs = [d for d in docs if ok(d.metadata or {})]
    def fn_tok(md):
        name = (md.get("source_file") or "").lower()
        return {
            "lh": "lh" in name or "ladies" in name or "girls" in name or "women" in name,
            "mh": "mh" in name or "mens" in name or "boys" in name,
            "nri": "nri" in name,
            "foreign": "foreign" in name,
            "indian": "indian" in name,
            "ay2025": "2025-26" in name or "2025_26" in name or "2025–26" in name,
        }
    scored = []
    want_lh = (filt.get("gender","") or "").lower()=="female"
    want_mh = (filt.get("gender","") or "").lower()=="male"
    want_nri = (filt.get("audience","") or "").lower()=="nri"
    want_foreign = (filt.get("audience","") or "").lower()=="foreign"
    want_indian = (filt.get("audience","") or "").lower()=="indian"
    want_ay2025 = "2025" in (filt.get("ay","") or "")
    for d in docs:
        md = d.metadata or {}
        tok = fn_tok(md)
        s = 0
        if want_lh and tok["lh"]: s+=3
        if want_mh and tok["mh"]: s+=3
        if want_nri and tok["nri"]: s+=2
        if want_foreign and tok["foreign"]: s+=2
        if want_indian and tok["indian"]: s+=2
        if want_ay2025 and tok["ay2025"]: s+=1
        s += keyword_score(d.page_content, query)
        scored.append((s,d))
    scored.sort(key=lambda x: x[0], reverse=True)
    return [d for s,d in scored][:topn]

def llm_summary(context: str, query: str) -> List[str]:
    try:
        import google.generativeai as genai
        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key: return []
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel("gemini-1.5-flash")
        prompt = f"""Summarize in 3 concise bullets using only the facts below.
STRICT: quote exact currency/amounts; no guesses.

Query: {query}
Context:
{context[:3000]}
"""
        resp = model.generate_content([{"role":"user","parts":[prompt]}],
                                      generation_config={"temperature":0.1,"max_output_tokens":220,"response_mime_type":"text/plain"})
        txt = (resp.text or "").strip()
        bullets = [re.sub(r"^\s*[-•]\s*","",ln).strip() for ln in txt.splitlines() if ln.strip()]
        return bullets[:5]
    except Exception:
        return []

def render_table_md(title: str, cols: List[str], rows: List[List[str]]) -> str:
    out = []
    if title: out.append(f"**{title}**")
    out.append("| " + " | ".join(cols) + " |")
    out.append("|" + "|".join(["---"]*len(cols)) + "|")
    for r in rows:
        out.append("| " + " | ".join("" if c is None else str(c) for c in r) + " |")
    out.append("")
    return "\n".join(out)

def answer_query(index_dir: Path, collection: str, query: str) -> str:
    # ---------- Structured (SQLite) routing ----------
    sr_intent = SR.detect_structured_intent(query)
    if sr_intent in ("tabular", "contacts", "blocks"):
        f = SR.parse_filters(query)
        if sr_intent == "contacts":
            data = SR.sql_block_contacts(f)
        elif sr_intent == "blocks":
            data = SR.sql_list_blocks(f)
        else:
            data = SR.sql_hostel_overview(f)

        cols = data["table"]["columns"][:]
        rows = [r[:] for r in data["table"]["rows"]]
        # hide source col if present
        if "Source" in cols:
            si = cols.index("Source")
            cols = cols[:si] + cols[si+1:]
            rows = [[c for j,c in enumerate(r) if j != si] for r in rows]

        seen = set(); clean_rows = []
        for r in rows:
            key = tuple("" if c is None else str(c).strip() for c in r)
            if key in seen: continue
            seen.add(key)
            clean_rows.append(r)

        md = render_table_md(data["table"].get("title","Results"), cols, clean_rows[:60])
        if data.get("bullets"):
            md += "\n**Quick overview:**\n" + "\n".join(f"- {b}" for b in data["bullets"])
        return md + "\n\n*Note: Structured answers are pulled from your SQLite DB built from official PDFs.*"

    # ---------- FAISS fallback for non-tabular ----------
    emb = GeminiLCEmbeddings()
    store = load_store(index_dir, collection, emb)

    filt = {}
    if any(k in query.lower() for k in ["hostel","block","mess","dhobi"]):
        filt["domain"] = "Hostel"
    docs = retrieve(store, query, k=40)
    docs = postfilter_and_rerank(docs, filt, query, topn=10)

    ctx_lines, sources = [], []
    for d in docs:
        md = d.metadata or {}
        src = md.get("source_file") or md.get("source_title") or "unknown"
        sources.append(src)
        head = f"[{src}] domain={md.get('domain')} category={md.get('category')} program={md.get('program')} audience={md.get('audience')} gender={md.get('gender')} ay={md.get('ay')}"
        ctx_lines += [head, d.page_content[:500], ""]
    context = "\n".join(ctx_lines)

    bullets = llm_summary(context, query)
    out = []
    if bullets:
        out.append("**Highlights:**")
        out += [f"- {b}" for b in bullets]
    else:
        out.append("_Couldn’t derive a concise summary from the retrieved context._")

    if sources:
        out.append("")
        out.append("*Sources:* " + ", ".join(list(dict.fromkeys(sources))[:5]))
    out.append("\n*Note: Answers are generated only from your ingested official PDFs.*")
    return "\n".join(out)

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--index_dir", required=True)
    ap.add_argument("--collection", default="vit_faq_vellore")
    ap.add_argument("--emb", choices=["gemini"], default="gemini")
    ap.add_argument("--q", required=True)
    args = ap.parse_args()
    print("\n" + answer_query(Path(args.index_dir), args.collection, args.q) + "\n")

if __name__ == "__main__":
    main()
