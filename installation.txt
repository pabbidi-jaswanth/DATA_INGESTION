from __future__ import annotations
import json, pathlib, pickle
from typing import List
import numpy as np
from scipy.sparse import load_npz
from sklearn.feature_extraction.text import TfidfVectorizer

def _paths(base_dir: pathlib.Path, collection: str):
    d = base_dir / collection
    return {"dir": d, "faiss": d / "index.faiss", "texts": d / "texts.json", "metas": d / "metas.json",
            "tfidf_vec": d / "vectorizer.pkl", "tfidf_mat": d / "tfidf_matrix.npz"}

def _mmr_select(embs: np.ndarray, query_vec: np.ndarray, k=6, lambda_div=0.65):
    sims = embs @ query_vec
    selected: List[int] = []
    candidates = list(range(len(sims)))
    while candidates and len(selected) < k:
        if not selected:
            best_local = int(np.argmax(sims[candidates]))
            selected.append(candidates.pop(best_local))
        else:
            q_scores = sims[candidates]
            div_scores = []
            for c in candidates:
                div_scores.append(float(np.max(embs[c] @ embs[selected].T)))
            div_scores = np.asarray(div_scores)
            mmr = lambda_div * q_scores - (1 - lambda_div) * div_scores
            best_local = int(np.argmax(mmr))
            selected.append(candidates.pop(best_local))
    return selected

def _format_snippets(texts, metas, indices: List[int]) -> str:
    lines = []
    for i in indices:
        t = texts[i]; m = metas[i]; doc = m.get("doc_name", "source")
        lines.append(f"- **{doc}**: {t[:1000]}{'...' if len(t) > 1000 else ''}")
    return "\n".join(lines)

def _try_import_faiss():
    try:
        import faiss
        return faiss
    except Exception:
        return None

def faiss_answer_or_summary(base_dir, collection, query: str, top_k: int = 10) -> str:
    base_dir = pathlib.Path(base_dir)
    p = _paths(base_dir, collection)
    if not p["texts"].exists() or not p["metas"].exists():
        return ""
    texts = json.loads(p["texts"].read_text(encoding="utf-8"))
    metas = json.loads(p["metas"].read_text(encoding="utf-8"))

    faiss = _try_import_faiss()
    if faiss is not None and p["faiss"].exists() and p["tfidf_vec"].exists():
        try:
            index = faiss.read_index(str(p["faiss"]))
            vectorizer: TfidfVectorizer = pickle.loads(p["tfidf_vec"].read_bytes())
            q_dense = vectorizer.transform([query]).toarray().astype(np.float32)
            D, I = index.search(q_dense, top_k)
            idxs = [int(i) for i in I[0] if i >= 0]
            if idxs:
                if p["tfidf_mat"].exists():
                    mat = load_npz(p["tfidf_mat"]).astype(np.float32)
                    pool = idxs + [i for i in range(min(len(texts), top_k * 2)) if i not in idxs]
                    pool_mat = mat[pool].toarray()
                    pool_mat /= (np.linalg.norm(pool_mat, axis=1, keepdims=True) + 1e-12)
                    qn = q_dense / (np.linalg.norm(q_dense) + 1e-12)
                    sel_local = _mmr_select(pool_mat, qn.reshape(-1), k=min(6, len(pool)))
                    chosen = [pool[i] for i in sel_local]
                    return _format_snippets(texts, metas, chosen)
                return _format_snippets(texts, metas, idxs[:6])
        except Exception:
            pass

    if not p["tfidf_vec"].exists() or not p["tfidf_mat"].exists():
        return ""
    vectorizer: TfidfVectorizer = pickle.loads(p["tfidf_vec"].read_bytes())
    mat = load_npz(p["tfidf_mat"])
    qv = vectorizer.transform([query])
    scores = (qv @ mat.T).toarray()[0]
    if scores.size == 0:
        return ""
    top = np.argsort(-scores)[: max(6, min(top_k, 10))]
    return _format_snippets(texts, metas, top.tolist())
